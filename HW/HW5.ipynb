{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "np.random.seed(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train original shape (60000, 28, 28)\n",
      "y_train original shape (60000,)\n",
      "X_test original shape (10000, 28, 28)\n",
      "y_test original shape (10000,)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "print(\"X_train original shape\", X_train.shape)\n",
    "print(\"y_train original shape\", y_train.shape)\n",
    "print(\"X_test original shape\", X_test.shape)\n",
    "print(\"y_test original shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Class 9')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0], cmap='gray')\n",
    "plt.title('Class '+ str(y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train/=255\n",
    "X_test/=255\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_classes = 10\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, number_of_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, number_of_classes)\n",
    "\n",
    "y_train[0], Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three steps to Convolution\n",
    "# 1. Convolution\n",
    "# 2. Activation\n",
    "# 3. Polling\n",
    "# Repeat Steps 1,2,3 for adding more hidden layers\n",
    "\n",
    "# 4. After that make a fully connected network\n",
    "# This fully connected network gives ability to the CNN\n",
    "# to classify the samples\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(28,28,1)))\n",
    "model.add(Activation('relu'))\n",
    "BatchNormalization(axis=-1)\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "BatchNormalization(axis=-1)\n",
    "model.add(Conv2D(64,(3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "BatchNormalization(axis=-1)\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "# Fully connected layer\n",
    "\n",
    "BatchNormalization()\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "BatchNormalization()\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10))\n",
    "\n",
    "# model.add(Convolution2D(10,3,3, border_mode='same'))\n",
    "# model.add(GlobalAveragePooling2D())\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 594,922\n",
      "Trainable params: 594,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
    " height_shift_range=0.08, zoom_range=0.08)\n",
    "\n",
    "test_gen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = gen.flow(X_train, Y_train, batch_size=64)\n",
    "test_generator = test_gen.flow(X_test, Y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "937/937 [==============================] - 64s 69ms/step - loss: 0.6219 - acc: 0.7630 - val_loss: 0.4108 - val_acc: 0.8454\n",
      "Epoch 2/5\n",
      "937/937 [==============================] - 62s 66ms/step - loss: 0.4075 - acc: 0.8465 - val_loss: 0.3012 - val_acc: 0.8868\n",
      "Epoch 3/5\n",
      "937/937 [==============================] - 58s 62ms/step - loss: 0.3456 - acc: 0.8709 - val_loss: 0.2819 - val_acc: 0.8956\n",
      "Epoch 4/5\n",
      "937/937 [==============================] - 59s 63ms/step - loss: 0.3115 - acc: 0.8840 - val_loss: 0.2801 - val_acc: 0.8961\n",
      "Epoch 5/5\n",
      "937/937 [==============================] - 59s 63ms/step - loss: 0.2947 - acc: 0.8897 - val_loss: 0.2509 - val_acc: 0.9061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb4db83470>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.fit(X_train, Y_train, batch_size=128, nb_epoch=1, validation_data=(X_test, Y_test))\n",
    "\n",
    "model.fit_generator(train_generator, steps_per_epoch=60000//64, epochs=5, \n",
    " validation_data=test_generator, validation_steps=10000//64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 327us/step\n",
      "\n",
      "Test accuracy:  0.9061\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)\n",
    "print()\n",
    "print('Test accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(X_test)\n",
    "\n",
    "predictions = list(predictions)\n",
    "actuals = list(y_test)\n",
    "\n",
    "sub = pd.DataFrame({'Actual': actuals, 'Predictions': predictions})\n",
    "sub.to_csv('./output_cnn_fashion.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
