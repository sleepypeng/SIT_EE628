{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io, color, transform\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193.05322170257568\n",
      "(25000, 784)\n",
      "(12500, 784)\n"
     ]
    }
   ],
   "source": [
    "# Read data set\n",
    "data_dir = '/Users/kunpenghao/Desktop/Study_in_SIT/EE_628/project'\n",
    "test_str = data_dir + '/data/test1/*.jpg'\n",
    "train_str = data_dir + '/data/train/*.jpg'\n",
    "\n",
    "def convert_gray(f): \n",
    "    rgb = io.imread(f)\n",
    "    rgb = transform.resize(rgb, (28, 28))\n",
    "    return color.rgb2gray(rgb)\n",
    "\n",
    "test_im = io.ImageCollection(test_str, load_func = convert_gray)\n",
    "train_im = io.ImageCollection(train_str, load_func = convert_gray)\n",
    "\n",
    "train = [0 for i in range(25000)]\n",
    "test = [0 for i in range(12500)]\n",
    "\n",
    "time_start = time.time()\n",
    "for i in range(len(train_im)):\n",
    "    pic = train_im[i]\n",
    "    train[i] = pic\n",
    "for i in range(len(test_im)):\n",
    "    pic = test_im[i]\n",
    "    test[i] = pic\n",
    "time_end = time.time()\n",
    "print(time_end - time_start)\n",
    "\n",
    "train = np.array(train)\n",
    "test = np.array(test)\n",
    "\n",
    "train = train.reshape((len(train), np.prod(train.shape[1:])))\n",
    "test = test.reshape((len(test), np.prod(test.shape[1:])))\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make class for train_set\n",
    "# x_train(20000), 0-9999 cat; 10000-19999 dog\n",
    "# x_val(5000), 0-2499 cat; 2500-4999 dog\n",
    "# y_train(20000) y_val(5000), cat = 1, dog = 0\n",
    "cat_train = train[:10000]\n",
    "cat_val = train[10000:12500]\n",
    "dog_train = train[12500:22500]\n",
    "dog_val = train[22500:]\n",
    "x_train = np.zeros([20000, 784])\n",
    "x_val = np.zeros([5000, 784])\n",
    "x_train[:10000] = cat_train\n",
    "x_train[10000:] = dog_train\n",
    "x_val[:2500] = cat_val\n",
    "x_val[2500:] = dog_val\n",
    "y_train = np.zeros([20000, 1])\n",
    "y_val = np.zeros([5000, 1])\n",
    "y_train[10000:] = 1\n",
    "y_val[2500:] = 1\n",
    "\n",
    "#y_train = y_train.tolist()\n",
    "#y_val = y_val.tolist()\n",
    "#x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "#x_val = x_val.reshape(x_val.shape[0], 28, 28, 1)\n",
    "#x_test = test.reshape(test.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = x_train.shape[1]\n",
    "num_class = 2\n",
    "\n",
    "autoencoder = Sequential()\n",
    "autoencoder.add(Dense(512, activation='relu'))\n",
    "autoencoder.add(Dense(128, activation='relu'))\n",
    "autoencoder.add(Dense(32, activation='relu'))\n",
    "autoencoder.add(Dense(2, activation='sigmoid'))\n",
    "autoencoder.add(Dense(32, activation='relu'))\n",
    "autoencoder.add(Dense(128, activation='relu'))\n",
    "autoencoder.add(Dense(512, activation='relu'))\n",
    "autoencoder.add(Dense(input_dim, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "20000/20000 [==============================] - 4s 216us/step - loss: 0.0650 - val_loss: 0.0654\n",
      "Epoch 2/50\n",
      "20000/20000 [==============================] - 3s 149us/step - loss: 0.0650 - val_loss: 0.0654\n",
      "Epoch 3/50\n",
      "20000/20000 [==============================] - 3s 156us/step - loss: 0.0649 - val_loss: 0.0653\n",
      "Epoch 4/50\n",
      "20000/20000 [==============================] - 3s 154us/step - loss: 0.0648 - val_loss: 0.0652\n",
      "Epoch 5/50\n",
      "20000/20000 [==============================] - 3s 153us/step - loss: 0.0647 - val_loss: 0.0651\n",
      "Epoch 6/50\n",
      "20000/20000 [==============================] - 3s 154us/step - loss: 0.0646 - val_loss: 0.0651\n",
      "Epoch 7/50\n",
      "20000/20000 [==============================] - 3s 160us/step - loss: 0.0646 - val_loss: 0.0650\n",
      "Epoch 8/50\n",
      "20000/20000 [==============================] - 3s 155us/step - loss: 0.0645 - val_loss: 0.0649\n",
      "Epoch 9/50\n",
      "20000/20000 [==============================] - 3s 156us/step - loss: 0.0644 - val_loss: 0.0648\n",
      "Epoch 10/50\n",
      "20000/20000 [==============================] - 3s 157us/step - loss: 0.0643 - val_loss: 0.0648\n",
      "Epoch 11/50\n",
      "20000/20000 [==============================] - 3s 157us/step - loss: 0.0642 - val_loss: 0.0647\n",
      "Epoch 12/50\n",
      "20000/20000 [==============================] - 3s 157us/step - loss: 0.0641 - val_loss: 0.0646\n",
      "Epoch 13/50\n",
      "20000/20000 [==============================] - 3s 162us/step - loss: 0.0640 - val_loss: 0.0645\n",
      "Epoch 14/50\n",
      "20000/20000 [==============================] - 3s 158us/step - loss: 0.0639 - val_loss: 0.0644\n",
      "Epoch 15/50\n",
      "20000/20000 [==============================] - 3s 157us/step - loss: 0.0638 - val_loss: 0.0643\n",
      "Epoch 16/50\n",
      "20000/20000 [==============================] - 3s 162us/step - loss: 0.0637 - val_loss: 0.0642\n",
      "Epoch 17/50\n",
      "20000/20000 [==============================] - 3s 158us/step - loss: 0.0636 - val_loss: 0.0641\n",
      "Epoch 18/50\n",
      "20000/20000 [==============================] - 3s 162us/step - loss: 0.0635 - val_loss: 0.0641\n",
      "Epoch 19/50\n",
      "20000/20000 [==============================] - 3s 157us/step - loss: 0.0634 - val_loss: 0.0640\n",
      "Epoch 20/50\n",
      "20000/20000 [==============================] - 3s 157us/step - loss: 0.0633 - val_loss: 0.0639\n",
      "Epoch 21/50\n",
      "20000/20000 [==============================] - 3s 157us/step - loss: 0.0632 - val_loss: 0.0638\n",
      "Epoch 22/50\n",
      "20000/20000 [==============================] - 3s 157us/step - loss: 0.0631 - val_loss: 0.0637\n",
      "Epoch 23/50\n",
      "20000/20000 [==============================] - 3s 162us/step - loss: 0.0630 - val_loss: 0.0636\n",
      "Epoch 24/50\n",
      "20000/20000 [==============================] - 3s 156us/step - loss: 0.0629 - val_loss: 0.0635\n",
      "Epoch 25/50\n",
      "20000/20000 [==============================] - 3s 157us/step - loss: 0.0628 - val_loss: 0.0634\n",
      "Epoch 26/50\n",
      "20000/20000 [==============================] - 3s 157us/step - loss: 0.0626 - val_loss: 0.0632\n",
      "Epoch 27/50\n",
      "20000/20000 [==============================] - 3s 159us/step - loss: 0.0625 - val_loss: 0.0630\n",
      "Epoch 28/50\n",
      "20000/20000 [==============================] - 3s 164us/step - loss: 0.0622 - val_loss: 0.0627\n",
      "Epoch 29/50\n",
      "20000/20000 [==============================] - 3s 157us/step - loss: 0.0619 - val_loss: 0.0623\n",
      "Epoch 30/50\n",
      "20000/20000 [==============================] - 3s 157us/step - loss: 0.0614 - val_loss: 0.0618\n",
      "Epoch 31/50\n",
      "20000/20000 [==============================] - 3s 167us/step - loss: 0.0607 - val_loss: 0.0610\n",
      "Epoch 32/50\n",
      "20000/20000 [==============================] - 3s 167us/step - loss: 0.0599 - val_loss: 0.0601\n",
      "Epoch 33/50\n",
      "20000/20000 [==============================] - 3s 163us/step - loss: 0.0588 - val_loss: 0.0590\n",
      "Epoch 34/50\n",
      "20000/20000 [==============================] - 3s 160us/step - loss: 0.0578 - val_loss: 0.0580\n",
      "Epoch 35/50\n",
      "20000/20000 [==============================] - 3s 160us/step - loss: 0.0570 - val_loss: 0.0578\n",
      "Epoch 36/50\n",
      "20000/20000 [==============================] - 3s 163us/step - loss: 0.0564 - val_loss: 0.0573\n",
      "Epoch 37/50\n",
      "20000/20000 [==============================] - 3s 164us/step - loss: 0.0559 - val_loss: 0.0564\n",
      "Epoch 38/50\n",
      "20000/20000 [==============================] - 3s 166us/step - loss: 0.0554 - val_loss: 0.0560\n",
      "Epoch 39/50\n",
      "20000/20000 [==============================] - 3s 157us/step - loss: 0.0549 - val_loss: 0.0560\n",
      "Epoch 40/50\n",
      "20000/20000 [==============================] - 3s 164us/step - loss: 0.0546 - val_loss: 0.0548\n",
      "Epoch 41/50\n",
      "20000/20000 [==============================] - 3s 164us/step - loss: 0.0541 - val_loss: 0.0550\n",
      "Epoch 42/50\n",
      "20000/20000 [==============================] - 3s 162us/step - loss: 0.0537 - val_loss: 0.0547\n",
      "Epoch 43/50\n",
      "20000/20000 [==============================] - 3s 163us/step - loss: 0.0533 - val_loss: 0.0533\n",
      "Epoch 44/50\n",
      "20000/20000 [==============================] - 3s 164us/step - loss: 0.0530 - val_loss: 0.0540\n",
      "Epoch 45/50\n",
      "20000/20000 [==============================] - 3s 168us/step - loss: 0.0527 - val_loss: 0.0529\n",
      "Epoch 46/50\n",
      "20000/20000 [==============================] - 3s 164us/step - loss: 0.0526 - val_loss: 0.0538\n",
      "Epoch 47/50\n",
      "20000/20000 [==============================] - 3s 166us/step - loss: 0.0523 - val_loss: 0.0533\n",
      "Epoch 48/50\n",
      "20000/20000 [==============================] - 3s 164us/step - loss: 0.0522 - val_loss: 0.0526\n",
      "Epoch 49/50\n",
      "20000/20000 [==============================] - 3s 170us/step - loss: 0.0522 - val_loss: 0.0522\n",
      "Epoch 50/50\n",
      "20000/20000 [==============================] - 3s 166us/step - loss: 0.0521 - val_loss: 0.0524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c1333fcf8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.compile(optimizer='Adadelta', loss='mse')\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_val, x_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Sequential()\n",
    "encoder.add(autoencoder.layers[0])\n",
    "encoder.add(autoencoder.layers[1])\n",
    "encoder.add(autoencoder.layers[2])\n",
    "encoder.add(autoencoder.layers[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "predictions = encoder.predict_classes(test)\n",
    "predictions = list(predictions)\n",
    "pic = []\n",
    "for i in range(12500):\n",
    "    pic.append(i+1)\n",
    "\n",
    "sub = pd.DataFrame({'id': pic,'label': predictions})\n",
    "sub.to_csv('./DeepAE_output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
