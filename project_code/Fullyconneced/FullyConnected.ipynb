{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io, color, transform\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202.6029109954834\n",
      "(25000, 784)\n",
      "(12500, 784)\n"
     ]
    }
   ],
   "source": [
    "# Read data set\n",
    "data_dir = '/Users/kunpenghao/Desktop/Study_in_SIT/EE_628/project'\n",
    "test_str = data_dir + '/data/test1/*.jpg'\n",
    "train_str = data_dir + '/data/train/*.jpg'\n",
    "\n",
    "def convert_gray(f): \n",
    "    rgb = io.imread(f)\n",
    "    rgb = transform.resize(rgb, (28, 28))\n",
    "    return color.rgb2gray(rgb)\n",
    "\n",
    "test_im = io.ImageCollection(test_str, load_func = convert_gray)\n",
    "train_im = io.ImageCollection(train_str, load_func = convert_gray)\n",
    "\n",
    "train = [0 for i in range(25000)]\n",
    "test = [0 for i in range(12500)]\n",
    "\n",
    "time_start = time.time()\n",
    "for i in range(len(train_im)):\n",
    "    pic = train_im[i]\n",
    "    train[i] = pic\n",
    "for i in range(len(test_im)):\n",
    "    pic = test_im[i]\n",
    "    test[i] = pic\n",
    "time_end = time.time()\n",
    "print(time_end - time_start)\n",
    "\n",
    "train = np.array(train)\n",
    "test = np.array(test)\n",
    "\n",
    "train = train.reshape((len(train), np.prod(train.shape[1:])))\n",
    "test = test.reshape((len(test), np.prod(test.shape[1:])))\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make class for train_set\n",
    "# x_train(20000), 0-9999 cat; 10000-19999 dog\n",
    "# x_val(5000), 0-2499 cat; 2500-4999 dog\n",
    "# y_train(20000) y_val(5000), cat = 1, dog = 0\n",
    "cat_train = train[:10000]\n",
    "cat_val = train[10000:12500]\n",
    "dog_train = train[12500:22500]\n",
    "dog_val = train[22500:]\n",
    "x_train = np.zeros([20000, 784])\n",
    "x_val = np.zeros([5000, 784])\n",
    "x_train[:10000] = cat_train\n",
    "x_train[10000:] = dog_train\n",
    "x_val[:2500] = cat_val\n",
    "x_val[2500:] = dog_val\n",
    "y_train = np.zeros([20000, 1])\n",
    "y_val = np.zeros([5000, 1])\n",
    "y_train[10000:] = 1\n",
    "y_val[2500:] = 1\n",
    "\n",
    "#y_train = y_train.tolist()\n",
    "#y_val = y_val.tolist()\n",
    "#x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "#x_val = x_val.reshape(x_val.shape[0], 28, 28, 1)\n",
    "#x_test = test.reshape(test.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.]), array([1., 0.], dtype=float32))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "number_of_classes = 2\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, number_of_classes)\n",
    "Y_val = np_utils.to_categorical(y_val, number_of_classes)\n",
    "\n",
    "y_train[0], Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Lambda\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "BatchNormalization()\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "BatchNormalization()\n",
    "model.add(Dense(32))\n",
    "model.add(Activation('relu'))\n",
    "BatchNormalization()\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "20000/20000 [==============================] - 2s 122us/step - loss: 0.6986 - acc: 0.5255 - val_loss: 0.6796 - val_acc: 0.5660\n",
      "Epoch 2/50\n",
      "20000/20000 [==============================] - 1s 60us/step - loss: 0.6846 - acc: 0.5522 - val_loss: 0.6711 - val_acc: 0.5882\n",
      "Epoch 3/50\n",
      "20000/20000 [==============================] - 1s 61us/step - loss: 0.6753 - acc: 0.5752 - val_loss: 0.6718 - val_acc: 0.5806\n",
      "Epoch 4/50\n",
      "20000/20000 [==============================] - 1s 62us/step - loss: 0.6749 - acc: 0.5725 - val_loss: 0.6610 - val_acc: 0.5952\n",
      "Epoch 5/50\n",
      "20000/20000 [==============================] - 1s 62us/step - loss: 0.6653 - acc: 0.5984 - val_loss: 0.6655 - val_acc: 0.5978\n",
      "Epoch 6/50\n",
      "20000/20000 [==============================] - 1s 61us/step - loss: 0.6635 - acc: 0.5993 - val_loss: 0.6597 - val_acc: 0.6048\n",
      "Epoch 7/50\n",
      "20000/20000 [==============================] - 1s 62us/step - loss: 0.6589 - acc: 0.6090 - val_loss: 0.6589 - val_acc: 0.6042\n",
      "Epoch 8/50\n",
      "20000/20000 [==============================] - 1s 62us/step - loss: 0.6548 - acc: 0.6109 - val_loss: 0.6617 - val_acc: 0.6000\n",
      "Epoch 9/50\n",
      "20000/20000 [==============================] - 1s 63us/step - loss: 0.6524 - acc: 0.6167 - val_loss: 0.6716 - val_acc: 0.5818\n",
      "Epoch 10/50\n",
      "20000/20000 [==============================] - 1s 63us/step - loss: 0.6535 - acc: 0.6164 - val_loss: 0.6643 - val_acc: 0.6052\n",
      "Epoch 11/50\n",
      "20000/20000 [==============================] - 1s 63us/step - loss: 0.6497 - acc: 0.6193 - val_loss: 0.6540 - val_acc: 0.6162\n",
      "Epoch 12/50\n",
      "20000/20000 [==============================] - 1s 64us/step - loss: 0.6445 - acc: 0.6280 - val_loss: 0.6658 - val_acc: 0.6094\n",
      "Epoch 13/50\n",
      "20000/20000 [==============================] - 1s 64us/step - loss: 0.6488 - acc: 0.6217 - val_loss: 0.6521 - val_acc: 0.6150\n",
      "Epoch 14/50\n",
      "20000/20000 [==============================] - 1s 63us/step - loss: 0.6426 - acc: 0.6321 - val_loss: 0.6517 - val_acc: 0.6148\n",
      "Epoch 15/50\n",
      "20000/20000 [==============================] - 1s 64us/step - loss: 0.6421 - acc: 0.6305 - val_loss: 0.6487 - val_acc: 0.6204\n",
      "Epoch 16/50\n",
      "20000/20000 [==============================] - 1s 64us/step - loss: 0.6346 - acc: 0.6392 - val_loss: 0.6451 - val_acc: 0.6176\n",
      "Epoch 17/50\n",
      "20000/20000 [==============================] - 1s 64us/step - loss: 0.6327 - acc: 0.6402 - val_loss: 0.6628 - val_acc: 0.5930\n",
      "Epoch 18/50\n",
      "20000/20000 [==============================] - 1s 64us/step - loss: 0.6411 - acc: 0.6272 - val_loss: 0.6612 - val_acc: 0.5840\n",
      "Epoch 19/50\n",
      "20000/20000 [==============================] - 1s 64us/step - loss: 0.6337 - acc: 0.6371 - val_loss: 0.6452 - val_acc: 0.6226\n",
      "Epoch 20/50\n",
      "20000/20000 [==============================] - 1s 65us/step - loss: 0.6301 - acc: 0.6430 - val_loss: 0.6463 - val_acc: 0.6252\n",
      "Epoch 21/50\n",
      "20000/20000 [==============================] - 1s 65us/step - loss: 0.6250 - acc: 0.6529 - val_loss: 0.6541 - val_acc: 0.6222\n",
      "Epoch 22/50\n",
      "20000/20000 [==============================] - 1s 65us/step - loss: 0.6247 - acc: 0.6491 - val_loss: 0.6513 - val_acc: 0.6264\n",
      "Epoch 23/50\n",
      "20000/20000 [==============================] - 1s 65us/step - loss: 0.6228 - acc: 0.6554 - val_loss: 0.6426 - val_acc: 0.6238\n",
      "Epoch 24/50\n",
      "20000/20000 [==============================] - 1s 65us/step - loss: 0.6233 - acc: 0.6467 - val_loss: 0.6442 - val_acc: 0.6262\n",
      "Epoch 25/50\n",
      "20000/20000 [==============================] - 1s 65us/step - loss: 0.6189 - acc: 0.6556 - val_loss: 0.6411 - val_acc: 0.6292\n",
      "Epoch 26/50\n",
      "20000/20000 [==============================] - 1s 65us/step - loss: 0.6161 - acc: 0.6592 - val_loss: 0.6466 - val_acc: 0.6246\n",
      "Epoch 27/50\n",
      "20000/20000 [==============================] - 1s 65us/step - loss: 0.6124 - acc: 0.6626 - val_loss: 0.6408 - val_acc: 0.6344\n",
      "Epoch 28/50\n",
      "20000/20000 [==============================] - 1s 65us/step - loss: 0.6113 - acc: 0.6610 - val_loss: 0.6483 - val_acc: 0.6314\n",
      "Epoch 29/50\n",
      "20000/20000 [==============================] - 1s 66us/step - loss: 0.6093 - acc: 0.6646 - val_loss: 0.6541 - val_acc: 0.6262\n",
      "Epoch 30/50\n",
      "20000/20000 [==============================] - 1s 65us/step - loss: 0.6096 - acc: 0.6653 - val_loss: 0.6556 - val_acc: 0.6188\n",
      "Epoch 31/50\n",
      "20000/20000 [==============================] - 1s 66us/step - loss: 0.6039 - acc: 0.6690 - val_loss: 0.6453 - val_acc: 0.6250\n",
      "Epoch 32/50\n",
      "20000/20000 [==============================] - 1s 66us/step - loss: 0.6007 - acc: 0.6723 - val_loss: 0.6469 - val_acc: 0.6244\n",
      "Epoch 33/50\n",
      "20000/20000 [==============================] - 1s 66us/step - loss: 0.6013 - acc: 0.6713 - val_loss: 0.6529 - val_acc: 0.6210\n",
      "Epoch 34/50\n",
      "20000/20000 [==============================] - 1s 66us/step - loss: 0.5942 - acc: 0.6751 - val_loss: 0.6462 - val_acc: 0.6354\n",
      "Epoch 35/50\n",
      "20000/20000 [==============================] - 1s 66us/step - loss: 0.5929 - acc: 0.6791 - val_loss: 0.6578 - val_acc: 0.6290\n",
      "Epoch 36/50\n",
      "20000/20000 [==============================] - 1s 66us/step - loss: 0.5921 - acc: 0.6764 - val_loss: 0.6532 - val_acc: 0.6290\n",
      "Epoch 37/50\n",
      "20000/20000 [==============================] - 1s 67us/step - loss: 0.5828 - acc: 0.6865 - val_loss: 0.6716 - val_acc: 0.6206\n",
      "Epoch 38/50\n",
      "20000/20000 [==============================] - 2s 81us/step - loss: 0.5922 - acc: 0.6771 - val_loss: 0.6432 - val_acc: 0.6330\n",
      "Epoch 39/50\n",
      "20000/20000 [==============================] - 2s 75us/step - loss: 0.5861 - acc: 0.6871 - val_loss: 0.6616 - val_acc: 0.6294\n",
      "Epoch 40/50\n",
      "20000/20000 [==============================] - 1s 75us/step - loss: 0.5858 - acc: 0.6846 - val_loss: 0.6715 - val_acc: 0.6248\n",
      "Epoch 41/50\n",
      "20000/20000 [==============================] - 1s 68us/step - loss: 0.5761 - acc: 0.6961 - val_loss: 0.6661 - val_acc: 0.6204\n",
      "Epoch 42/50\n",
      "20000/20000 [==============================] - 1s 68us/step - loss: 0.5740 - acc: 0.6973 - val_loss: 0.6661 - val_acc: 0.6324\n",
      "Epoch 43/50\n",
      "20000/20000 [==============================] - 1s 67us/step - loss: 0.5663 - acc: 0.7036 - val_loss: 0.6721 - val_acc: 0.6272\n",
      "Epoch 44/50\n",
      "20000/20000 [==============================] - 1s 67us/step - loss: 0.5702 - acc: 0.6973 - val_loss: 0.6591 - val_acc: 0.6230\n",
      "Epoch 45/50\n",
      "20000/20000 [==============================] - 1s 67us/step - loss: 0.5615 - acc: 0.7007 - val_loss: 0.6670 - val_acc: 0.6214\n",
      "Epoch 46/50\n",
      "20000/20000 [==============================] - 1s 74us/step - loss: 0.5628 - acc: 0.7028 - val_loss: 0.6550 - val_acc: 0.6258\n",
      "Epoch 47/50\n",
      "20000/20000 [==============================] - 1s 72us/step - loss: 0.5656 - acc: 0.6990 - val_loss: 0.6814 - val_acc: 0.6238\n",
      "Epoch 48/50\n",
      "20000/20000 [==============================] - 1s 67us/step - loss: 0.5633 - acc: 0.7018 - val_loss: 0.6770 - val_acc: 0.6214\n",
      "Epoch 49/50\n",
      "20000/20000 [==============================] - 1s 66us/step - loss: 0.5688 - acc: 0.6968 - val_loss: 0.6605 - val_acc: 0.6242\n",
      "Epoch 50/50\n",
      "20000/20000 [==============================] - 1s 73us/step - loss: 0.5705 - acc: 0.6966 - val_loss: 0.6563 - val_acc: 0.6386\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c492abf98>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "model.fit(x_train, Y_train,\n",
    "                epochs=50,\n",
    "                batch_size=512,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 47us/step\n",
      "Test accuracy:  0.6386\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_val, Y_val)\n",
    "print('Test accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "predictions = model.predict_classes(test)\n",
    "predictions = list(predictions)\n",
    "pic = []\n",
    "for i in range(12500):\n",
    "    pic.append(i+1)\n",
    "\n",
    "sub = pd.DataFrame({'id': pic,'label': predictions})\n",
    "sub.to_csv('./FullyConnected_output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
